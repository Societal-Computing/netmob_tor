{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9fda75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "from shapely.geometry import MultiPoint\n",
    "from geopy.distance import great_circle\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import duckdb\n",
    "import awscli\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f98663",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = ['Bordeaux', 'Clermont-Ferrand', 'Dijon', 'Grenoble', 'Lille',\n",
    "                 'Lyon', 'Mans', 'Marseille', 'Metz', 'Montpellier',\n",
    "                 'Nancy', 'Nantes', 'Nice', 'Orleans', 'Paris',\n",
    "                 'Rennes', 'Saint-Etienne', 'Strasbourg', 'Toulouse', 'Tours']\n",
    "\n",
    "apps = ['Web_Adult', 'Tor', 'YouTube']\n",
    "\n",
    "traffic_dir = ['DL']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6e8f39-d867-4276-9248-792b0525736b",
   "metadata": {},
   "source": [
    "### Sum tile-level activity across time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b94d4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "nighttime = list(range(29)) + list(range(88, 97))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f6863b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for city_str in cities:\n",
    "    for app_str in apps:\n",
    "        for rate_str in traffic_dir:\n",
    "            \n",
    "            df_1 = pd.DataFrame()\n",
    "            \n",
    "            for month in range(3, 6):\n",
    "              print(\"Month\", month, \"in\", city_str, \"for\", app_str, rate_str)\n",
    "              traffic = dict()\n",
    "              s = 1\n",
    "              if month == 3:\n",
    "                s = 16\n",
    "              if month == 4:\n",
    "                n = 31\n",
    "              else:\n",
    "                n = 32\n",
    "              for day in tqdm(range(s, n)):\n",
    "                day_index = day\n",
    "                if day < 10:\n",
    "                  day_str = f'20190{month}0{day}'\n",
    "                else:\n",
    "                  day_str = f'20190{month}{day}'\n",
    "\n",
    "                df_2 = pd.read_csv(f'../Data/Netmob/{city_str}/{app_str}/{day_str}/{city_str}_{app_str}_{day_str}_{rate_str}.txt', sep = \" \", header=None)\n",
    "                \n",
    "                col_list= list(df_2)\n",
    "                col_list.remove(0)\n",
    "\n",
    "                df_2[day_str] = df_2[col_list].sum(axis=1)\n",
    "                \n",
    "                df_2 = df_2[[0, day_str]].copy().rename(columns={0: \"tile_id\"})\n",
    "                \n",
    "                if df_1.empty:\n",
    "                    df_1 = df_2.copy()\n",
    "                else:\n",
    "                    df_1 = df_1.merge(df_2, how = 'left', on = 'tile_id')\n",
    "            \n",
    "            df_1_list = list(df_1)\n",
    "            df_1_list.remove('tile_id')\n",
    "            \n",
    "            df_1['traffic_sum'] = df_1[df_1_list].sum(axis=1)\n",
    "            df_1['traffic_mean'] = df_1[df_1_list].mean(axis=1)\n",
    "            \n",
    "            df_1 = df_1[['tile_id', 'traffic_sum', 'traffic_mean']].copy()\n",
    "            \n",
    "            df_1[\"traffic_dir\"] = rate_str\n",
    "            df_1[\"apps\"] = app_str\n",
    "            df_1[\"cities\"] = city_str\n",
    "            \n",
    "            df = pd.concat([df,df_1])\n",
    "                \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12c46b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76ff2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d3d502-38c6-4aaa-9b03-8743437a4e57",
   "metadata": {},
   "source": [
    "### Identify top active tiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04825d24",
   "metadata": {},
   "source": [
    "Add cpc correction factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b060db6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_df = gpd.read_file(\"../midsave/map_crime.gpkg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d780835",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpc = pd.read_csv(\"../midsave/cpc_com.csv\", dtype={'code_com': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6357f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee286a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0367777f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (df\n",
    "      .merge(map_df[['tile_id', 'code_com', 'name_com', 'cities']], on = ['tile_id', 'cities'], how = 'left')\n",
    "      .merge(cpc[['code_com', 'c']], on = ['code_com'], how = 'left'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135f8718",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tor_scaled'] = df['traffic_mean']*df['c']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32ffa60",
   "metadata": {},
   "source": [
    "Number of top tiles inspected (or alternatively top X%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73e07d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(df.shape[0]*0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589b399a-217e-49a7-8c94-cc529531a32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b9f5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10 = (df\n",
    "    .query(\"apps == 'Tor'\")\n",
    "    .query(\"traffic_dir == 'DL'\")\n",
    "    .nlargest(n, 'Tor_scaled'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5773b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10.cities.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9828df",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_tiles = pd.DataFrame()\n",
    "\n",
    "for city_str in top10.cities.unique():\n",
    "    \n",
    "    shape = gpd.read_file(f'../Data/Netmob/{city_str}/{city_str}.geojson')\n",
    "    \n",
    "    shape['cities'] = city_str\n",
    "    \n",
    "    tmp = top10.merge(shape, how = 'inner', on = ['tile_id','cities'])\n",
    "    \n",
    "    if top_tiles.empty:\n",
    "        top_tiles = tmp\n",
    "    else:\n",
    "        top_tiles = pd.concat([top_tiles, tmp])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72504fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_tiles = (gpd.GeoDataFrame(top_tiles, crs=shape.crs, geometry=top_tiles['geometry'])\n",
    "             .nlargest(n, 'Tor_scaled')).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b964cd2",
   "metadata": {},
   "source": [
    "### Querying Overture maps for POI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ecafc3",
   "metadata": {},
   "source": [
    "#### For Tor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0049c10e",
   "metadata": {},
   "source": [
    "Only uncomment following line once to download Overture data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de8d49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aws s3 cp --region us-west-2 --no-sign-request --recursive s3://overturemaps-us-west-2/release/2023-07-26-alpha.0/theme=places/ /Users/tillkoebe/Documents/Data/Overture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e9d05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = duckdb.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98bf665",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = db.execute(\"\"\"\n",
    "select *\n",
    "from read_parquet('../Data/Overture/type=place/*')\n",
    "where\n",
    "    bbox.minx > -4.9857056141 \n",
    "    AND bbox.maxx < 8.4615600109 \n",
    "    AND bbox.miny > 42.1448396402 \n",
    "    AND bbox.maxy < 51.2187257569\n",
    "\"\"\")\n",
    "rows = cursor.fetchall()\n",
    "columns = [desc[0] for desc in cursor.description]\n",
    "dicts = [dict(zip(columns, row)) for row in rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c0a560",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d44fdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "overture_df = pd.DataFrame(data = [\n",
    "    {\n",
    "        'place_id': d['id'],\n",
    "        'name': d['names']['value'][0][0]['value'][0],\n",
    "        'category': d['categories']['main'],\n",
    "        'place_lon': (d['bbox']['maxx'] + d['bbox']['minx']) / 2,\n",
    "        'place_lat': (d['bbox']['maxy'] + d['bbox']['miny']) / 2\n",
    "    }\n",
    "    for d in dicts\n",
    "]\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556d9df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "overture_gdf = gpd.GeoDataFrame(\n",
    "    overture_df, geometry=gpd.points_from_xy(overture_df.place_lon, overture_df.place_lat), crs=shape.crs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ccd160",
   "metadata": {},
   "outputs": [],
   "source": [
    "overture_gdf.to_file(\"../midsave/overture.gpkg\", layer='overture', driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa27667",
   "metadata": {},
   "outputs": [],
   "source": [
    "overture_df['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71d7d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "overture_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37db02bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "overture_tor = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac4ac20",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(0, top_tiles.shape[0], 1)):\n",
    "    tiles_mask = overture_gdf.within(top_tiles.loc[i, 'geometry'])\n",
    "    temp = overture_gdf.loc[tiles_mask].copy()\n",
    "    temp['tile_id'] = top_tiles.loc[i, 'tile_id']\n",
    "    temp['cities'] = top_tiles.loc[i, 'cities']\n",
    "    temp['traffic_mean_tor'] = top_tiles.loc[i, 'Tor_scaled']\n",
    "    overture_tor = pd.concat([overture_tor, temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c28d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_divided_by_count(series):\n",
    "    return series.sum() / series.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41df400",
   "metadata": {},
   "outputs": [],
   "source": [
    "overture_tor['traffic_mean_tor_per_poi'] = overture_tor.groupby(['cities', 'tile_id'])['traffic_mean_tor'].transform('mean') / overture_tor.groupby(['cities', 'tile_id'])['traffic_mean_tor'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df77b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "(overture_tor\n",
    " .drop_duplicates(subset=['place_id'])\n",
    " .groupby(['category'])\n",
    " .agg({'traffic_mean_tor_per_poi': sum_divided_by_count, 'place_id': 'count'})\n",
    " .reset_index()\n",
    " .rename(columns={'place_id': 'category_count'})\n",
    " .sort_values(by=['traffic_mean_tor_per_poi'], ascending = False)\n",
    " .query('category_count >= 3')\n",
    " .head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86582839",
   "metadata": {},
   "source": [
    "#### For Web Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f10599",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_wa = (df\n",
    "    .query(\"apps == 'Web_Adult'\")\n",
    "    .query(\"traffic_dir == 'DL'\")\n",
    "    .nlargest(n, 'Tor_scaled'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c46dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_tiles_wa = pd.DataFrame()\n",
    "\n",
    "for city_str in top10_wa.cities.unique():\n",
    "    \n",
    "    shape = gpd.read_file(f'../Data/Netmob/{city_str}/{city_str}.geojson')\n",
    "    \n",
    "    shape['cities'] = city_str\n",
    "    \n",
    "    tmp = top10_wa.merge(shape, how = 'inner', on = ['tile_id','cities'])\n",
    "    \n",
    "    if top_tiles_wa.empty:\n",
    "        top_tiles_wa = tmp\n",
    "    else:\n",
    "        top_tiles_wa = pd.concat([top_tiles_wa, tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd74d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_tiles_wa = (gpd.GeoDataFrame(top_tiles_wa, crs=shape.crs, geometry=top_tiles_wa['geometry'])\n",
    "             .nlargest(n, 'Tor_scaled')).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7df157f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_tiles_wa.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e569cbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "overture_wa = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d067277e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(0, top_tiles_wa.shape[0], 1)):\n",
    "    tiles_mask = overture_gdf.within(top_tiles_wa.loc[i, 'geometry'])\n",
    "    temp = overture_gdf.loc[tiles_mask].copy()\n",
    "    temp['tile_id'] = top_tiles_wa.loc[i, 'tile_id']\n",
    "    temp['cities'] = top_tiles_wa.loc[i, 'cities']\n",
    "    temp['traffic_mean_wa'] = top_tiles_wa.loc[i, 'Tor_scaled']\n",
    "    overture_wa = pd.concat([overture_wa, temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07250b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "overture_wa['traffic_mean_wa_per_poi'] = overture_wa.groupby(['cities', 'tile_id'])['traffic_mean_wa'].transform('mean') / overture_wa.groupby(['cities', 'tile_id'])['traffic_mean_wa'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081e270b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(overture_wa\n",
    " .drop_duplicates(subset=['place_id'])\n",
    " .groupby(['category'])\n",
    " .agg({'traffic_mean_wa_per_poi': sum_divided_by_count, 'place_id': 'count'})\n",
    " .reset_index()\n",
    " .rename(columns={'place_id': 'category_count'})\n",
    " .sort_values(by=['traffic_mean_wa_per_poi'], ascending = False)\n",
    " .query('category_count >= 3')\n",
    " .head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140aa683",
   "metadata": {},
   "source": [
    "#### For YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536750fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_yt = (df\n",
    "    .query(\"apps == 'YouTube'\")\n",
    "    .query(\"traffic_dir == 'DL'\")\n",
    "    .nlargest(n, 'Tor_scaled'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4568453",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_tiles_yt = pd.DataFrame()\n",
    "\n",
    "for city_str in top10_yt.cities.unique():\n",
    "    \n",
    "    shape = gpd.read_file(f'../Data/Netmob/{city_str}/{city_str}.geojson')\n",
    "    \n",
    "    shape['cities'] = city_str\n",
    "    \n",
    "    tmp = top10_yt.merge(shape, how = 'inner', on = ['tile_id','cities'])\n",
    "    \n",
    "    if top_tiles_yt.empty:\n",
    "        top_tiles_yt = tmp\n",
    "    else:\n",
    "        top_tiles_yt = pd.concat([top_tiles_yt, tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d49fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_tiles_yt = (gpd.GeoDataFrame(top_tiles_yt, crs=shape.crs, geometry=top_tiles_yt['geometry'])\n",
    "             .nlargest(n, 'Tor_scaled')).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d24c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "overture_yt = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29baae55",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(0, top_tiles_yt.shape[0], 1)):\n",
    "    tiles_mask = overture_gdf.within(top_tiles_yt.loc[i, 'geometry'])\n",
    "    temp = overture_gdf.loc[tiles_mask].copy()\n",
    "    temp['tile_id'] = top_tiles_yt.loc[i, 'tile_id']\n",
    "    temp['cities'] = top_tiles_yt.loc[i, 'cities']\n",
    "    temp['traffic_mean_yt'] = top_tiles_yt.loc[i, 'Tor_scaled']\n",
    "    overture_yt = pd.concat([overture_yt, temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd78ffad",
   "metadata": {},
   "outputs": [],
   "source": [
    "overture_yt['traffic_mean_yt_per_poi'] = overture_yt.groupby(['cities', 'tile_id'])['traffic_mean_yt'].transform('mean') / overture_yt.groupby(['cities', 'tile_id'])['traffic_mean_yt'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac637e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(overture_yt\n",
    " .drop_duplicates(subset=['place_id'])\n",
    " .groupby(['category'])\n",
    " .agg({'traffic_mean_yt_per_poi': sum_divided_by_count, 'place_id': 'count'})\n",
    " .reset_index()\n",
    " .rename(columns={'place_id': 'category_count'})\n",
    " .sort_values(by=['traffic_mean_yt_per_poi'], ascending = False)\n",
    " .query('category_count >= 3')\n",
    " .head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
